{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./results/05-29-2019-19:05:43.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_start</th>\n",
       "      <th>train_end</th>\n",
       "      <th>test_start</th>\n",
       "      <th>test_end</th>\n",
       "      <th>model_type</th>\n",
       "      <th>clf</th>\n",
       "      <th>parameters</th>\n",
       "      <th>auc-roc</th>\n",
       "      <th>baseline_at_1</th>\n",
       "      <th>baseline_at_2</th>\n",
       "      <th>...</th>\n",
       "      <th>precision_at_20</th>\n",
       "      <th>precision_at_30</th>\n",
       "      <th>precision_at_50</th>\n",
       "      <th>recall_at_1</th>\n",
       "      <th>recall_at_2</th>\n",
       "      <th>recall_at_5</th>\n",
       "      <th>recall_at_10</th>\n",
       "      <th>recall_at_20</th>\n",
       "      <th>recall_at_30</th>\n",
       "      <th>recall_at_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>0.649453</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.390015</td>\n",
       "      <td>0.372528</td>\n",
       "      <td>0.376579</td>\n",
       "      <td>0.009465</td>\n",
       "      <td>0.015908</td>\n",
       "      <td>0.058941</td>\n",
       "      <td>0.094178</td>\n",
       "      <td>0.274022</td>\n",
       "      <td>0.392619</td>\n",
       "      <td>0.661470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=0.01, class_weight=None, ...</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l1'}</td>\n",
       "      <td>0.649891</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.439828</td>\n",
       "      <td>0.416830</td>\n",
       "      <td>0.375809</td>\n",
       "      <td>0.015749</td>\n",
       "      <td>0.033169</td>\n",
       "      <td>0.082883</td>\n",
       "      <td>0.162345</td>\n",
       "      <td>0.309020</td>\n",
       "      <td>0.439310</td>\n",
       "      <td>0.660118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>RF</td>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>0.688447</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456923</td>\n",
       "      <td>0.438415</td>\n",
       "      <td>0.397546</td>\n",
       "      <td>0.020840</td>\n",
       "      <td>0.038498</td>\n",
       "      <td>0.089405</td>\n",
       "      <td>0.173481</td>\n",
       "      <td>0.321031</td>\n",
       "      <td>0.462059</td>\n",
       "      <td>0.698298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>AB</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 100}</td>\n",
       "      <td>0.666279</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.436998</td>\n",
       "      <td>0.417509</td>\n",
       "      <td>0.381379</td>\n",
       "      <td>0.017738</td>\n",
       "      <td>0.035953</td>\n",
       "      <td>0.086064</td>\n",
       "      <td>0.165208</td>\n",
       "      <td>0.307031</td>\n",
       "      <td>0.440025</td>\n",
       "      <td>0.669901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>ET</td>\n",
       "      <td>ExtraTreesClassifier(bootstrap=False, class_we...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'max_fe...</td>\n",
       "      <td>0.634259</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.420469</td>\n",
       "      <td>0.398491</td>\n",
       "      <td>0.361364</td>\n",
       "      <td>0.018772</td>\n",
       "      <td>0.035396</td>\n",
       "      <td>0.082326</td>\n",
       "      <td>0.157731</td>\n",
       "      <td>0.295418</td>\n",
       "      <td>0.419981</td>\n",
       "      <td>0.634744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>BG</td>\n",
       "      <td>BaggingClassifier(base_estimator=None, bootstr...</td>\n",
       "      <td>{'max_features': 50, 'max_samples': 50, 'n_est...</td>\n",
       "      <td>0.537292</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334654</td>\n",
       "      <td>0.318868</td>\n",
       "      <td>0.332428</td>\n",
       "      <td>0.012249</td>\n",
       "      <td>0.029828</td>\n",
       "      <td>0.063315</td>\n",
       "      <td>0.117165</td>\n",
       "      <td>0.235126</td>\n",
       "      <td>0.336064</td>\n",
       "      <td>0.583917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>GB</td>\n",
       "      <td>GradientBoostingClassifier(criterion='friedman...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>0.667772</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444809</td>\n",
       "      <td>0.423774</td>\n",
       "      <td>0.386044</td>\n",
       "      <td>0.017579</td>\n",
       "      <td>0.034839</td>\n",
       "      <td>0.082962</td>\n",
       "      <td>0.163618</td>\n",
       "      <td>0.312520</td>\n",
       "      <td>0.446627</td>\n",
       "      <td>0.678094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-11-02</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>0.640871</td>\n",
       "      <td>0.004608</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.460493</td>\n",
       "      <td>0.423833</td>\n",
       "      <td>0.417028</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.016334</td>\n",
       "      <td>0.060668</td>\n",
       "      <td>0.114044</td>\n",
       "      <td>0.291527</td>\n",
       "      <td>0.402508</td>\n",
       "      <td>0.660055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-11-02</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=0.01, class_weight=None, ...</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l1'}</td>\n",
       "      <td>0.640417</td>\n",
       "      <td>0.004608</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.460723</td>\n",
       "      <td>0.448403</td>\n",
       "      <td>0.402377</td>\n",
       "      <td>0.017792</td>\n",
       "      <td>0.033834</td>\n",
       "      <td>0.082252</td>\n",
       "      <td>0.156482</td>\n",
       "      <td>0.291673</td>\n",
       "      <td>0.425842</td>\n",
       "      <td>0.636867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-11-02</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>RF</td>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>0.682569</td>\n",
       "      <td>0.004608</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505413</td>\n",
       "      <td>0.477887</td>\n",
       "      <td>0.431862</td>\n",
       "      <td>0.016480</td>\n",
       "      <td>0.035438</td>\n",
       "      <td>0.087648</td>\n",
       "      <td>0.170920</td>\n",
       "      <td>0.319965</td>\n",
       "      <td>0.453843</td>\n",
       "      <td>0.683535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-11-02</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>AB</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 100}</td>\n",
       "      <td>0.676769</td>\n",
       "      <td>0.004608</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502649</td>\n",
       "      <td>0.480498</td>\n",
       "      <td>0.424952</td>\n",
       "      <td>0.017938</td>\n",
       "      <td>0.034272</td>\n",
       "      <td>0.084439</td>\n",
       "      <td>0.165670</td>\n",
       "      <td>0.318215</td>\n",
       "      <td>0.456322</td>\n",
       "      <td>0.672597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-11-02</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>ET</td>\n",
       "      <td>ExtraTreesClassifier(bootstrap=False, class_we...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'max_fe...</td>\n",
       "      <td>0.623009</td>\n",
       "      <td>0.004608</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444368</td>\n",
       "      <td>0.425676</td>\n",
       "      <td>0.392795</td>\n",
       "      <td>0.014729</td>\n",
       "      <td>0.028730</td>\n",
       "      <td>0.073064</td>\n",
       "      <td>0.148024</td>\n",
       "      <td>0.281318</td>\n",
       "      <td>0.404258</td>\n",
       "      <td>0.621700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-11-02</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>BG</td>\n",
       "      <td>BaggingClassifier(base_estimator=None, bootstr...</td>\n",
       "      <td>{'max_features': 50, 'max_samples': 50, 'n_est...</td>\n",
       "      <td>0.558968</td>\n",
       "      <td>0.004608</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361437</td>\n",
       "      <td>0.354883</td>\n",
       "      <td>0.359163</td>\n",
       "      <td>0.013709</td>\n",
       "      <td>0.023625</td>\n",
       "      <td>0.066501</td>\n",
       "      <td>0.120461</td>\n",
       "      <td>0.228817</td>\n",
       "      <td>0.337028</td>\n",
       "      <td>0.568470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-11-02</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>GB</td>\n",
       "      <td>GradientBoostingClassifier(criterion='friedman...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>0.606796</td>\n",
       "      <td>0.004608</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.406358</td>\n",
       "      <td>0.405559</td>\n",
       "      <td>0.382567</td>\n",
       "      <td>0.012250</td>\n",
       "      <td>0.024792</td>\n",
       "      <td>0.066647</td>\n",
       "      <td>0.129357</td>\n",
       "      <td>0.257255</td>\n",
       "      <td>0.385154</td>\n",
       "      <td>0.605513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-05-02</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>0.620938</td>\n",
       "      <td>0.003040</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.287925</td>\n",
       "      <td>0.312399</td>\n",
       "      <td>0.331553</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.021375</td>\n",
       "      <td>0.063061</td>\n",
       "      <td>0.122697</td>\n",
       "      <td>0.224138</td>\n",
       "      <td>0.364785</td>\n",
       "      <td>0.645253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-05-02</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=0.01, class_weight=None, ...</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l1'}</td>\n",
       "      <td>0.624321</td>\n",
       "      <td>0.003040</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380916</td>\n",
       "      <td>0.363875</td>\n",
       "      <td>0.328519</td>\n",
       "      <td>0.018186</td>\n",
       "      <td>0.032829</td>\n",
       "      <td>0.076169</td>\n",
       "      <td>0.154346</td>\n",
       "      <td>0.296528</td>\n",
       "      <td>0.424894</td>\n",
       "      <td>0.639348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-05-02</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>RF</td>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>0.670367</td>\n",
       "      <td>0.003040</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.406098</td>\n",
       "      <td>0.385619</td>\n",
       "      <td>0.350485</td>\n",
       "      <td>0.019131</td>\n",
       "      <td>0.037317</td>\n",
       "      <td>0.091993</td>\n",
       "      <td>0.174303</td>\n",
       "      <td>0.316131</td>\n",
       "      <td>0.450283</td>\n",
       "      <td>0.682097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-05-02</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>AB</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 100}</td>\n",
       "      <td>0.657055</td>\n",
       "      <td>0.003040</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391383</td>\n",
       "      <td>0.369842</td>\n",
       "      <td>0.339502</td>\n",
       "      <td>0.015588</td>\n",
       "      <td>0.034837</td>\n",
       "      <td>0.078177</td>\n",
       "      <td>0.128248</td>\n",
       "      <td>0.304676</td>\n",
       "      <td>0.431861</td>\n",
       "      <td>0.660723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-05-02</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>ET</td>\n",
       "      <td>ExtraTreesClassifier(bootstrap=False, class_we...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'max_fe...</td>\n",
       "      <td>0.620706</td>\n",
       "      <td>0.003040</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372725</td>\n",
       "      <td>0.351436</td>\n",
       "      <td>0.321359</td>\n",
       "      <td>0.016769</td>\n",
       "      <td>0.033538</td>\n",
       "      <td>0.078059</td>\n",
       "      <td>0.154228</td>\n",
       "      <td>0.290151</td>\n",
       "      <td>0.410368</td>\n",
       "      <td>0.625413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-05-02</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>BG</td>\n",
       "      <td>BaggingClassifier(base_estimator=None, bootstr...</td>\n",
       "      <td>{'max_features': 50, 'max_samples': 50, 'n_est...</td>\n",
       "      <td>0.547968</td>\n",
       "      <td>0.003040</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291717</td>\n",
       "      <td>0.215008</td>\n",
       "      <td>0.366323</td>\n",
       "      <td>0.004724</td>\n",
       "      <td>0.020076</td>\n",
       "      <td>0.037907</td>\n",
       "      <td>0.098252</td>\n",
       "      <td>0.227090</td>\n",
       "      <td>0.251063</td>\n",
       "      <td>0.712919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-05-02</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>GB</td>\n",
       "      <td>GradientBoostingClassifier(criterion='friedman...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>0.625309</td>\n",
       "      <td>0.003040</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371056</td>\n",
       "      <td>0.353560</td>\n",
       "      <td>0.325667</td>\n",
       "      <td>0.016887</td>\n",
       "      <td>0.033774</td>\n",
       "      <td>0.080657</td>\n",
       "      <td>0.153991</td>\n",
       "      <td>0.288852</td>\n",
       "      <td>0.412848</td>\n",
       "      <td>0.633798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_start   train_end  test_start    test_end model_type  \\\n",
       "0   2012-01-01  2013-05-02  2013-07-01  2014-01-01         DT   \n",
       "1   2012-01-01  2013-05-02  2013-07-01  2014-01-01         LR   \n",
       "2   2012-01-01  2013-05-02  2013-07-01  2014-01-01         RF   \n",
       "3   2012-01-01  2013-05-02  2013-07-01  2014-01-01         AB   \n",
       "4   2012-01-01  2013-05-02  2013-07-01  2014-01-01         ET   \n",
       "5   2012-01-01  2013-05-02  2013-07-01  2014-01-01         BG   \n",
       "6   2012-01-01  2013-05-02  2013-07-01  2014-01-01         GB   \n",
       "7   2012-01-01  2012-11-02  2013-01-01  2013-07-01         DT   \n",
       "8   2012-01-01  2012-11-02  2013-01-01  2013-07-01         LR   \n",
       "9   2012-01-01  2012-11-02  2013-01-01  2013-07-01         RF   \n",
       "10  2012-01-01  2012-11-02  2013-01-01  2013-07-01         AB   \n",
       "11  2012-01-01  2012-11-02  2013-01-01  2013-07-01         ET   \n",
       "12  2012-01-01  2012-11-02  2013-01-01  2013-07-01         BG   \n",
       "13  2012-01-01  2012-11-02  2013-01-01  2013-07-01         GB   \n",
       "14  2012-01-01  2012-05-02  2012-07-01  2013-01-01         DT   \n",
       "15  2012-01-01  2012-05-02  2012-07-01  2013-01-01         LR   \n",
       "16  2012-01-01  2012-05-02  2012-07-01  2013-01-01         RF   \n",
       "17  2012-01-01  2012-05-02  2012-07-01  2013-01-01         AB   \n",
       "18  2012-01-01  2012-05-02  2012-07-01  2013-01-01         ET   \n",
       "19  2012-01-01  2012-05-02  2012-07-01  2013-01-01         BG   \n",
       "20  2012-01-01  2012-05-02  2012-07-01  2013-01-01         GB   \n",
       "\n",
       "                                                  clf  \\\n",
       "0   DecisionTreeClassifier(class_weight=None, crit...   \n",
       "1   LogisticRegression(C=0.01, class_weight=None, ...   \n",
       "2   RandomForestClassifier(bootstrap=True, class_w...   \n",
       "3   AdaBoostClassifier(algorithm='SAMME',\\n       ...   \n",
       "4   ExtraTreesClassifier(bootstrap=False, class_we...   \n",
       "5   BaggingClassifier(base_estimator=None, bootstr...   \n",
       "6   GradientBoostingClassifier(criterion='friedman...   \n",
       "7   DecisionTreeClassifier(class_weight=None, crit...   \n",
       "8   LogisticRegression(C=0.01, class_weight=None, ...   \n",
       "9   RandomForestClassifier(bootstrap=True, class_w...   \n",
       "10  AdaBoostClassifier(algorithm='SAMME',\\n       ...   \n",
       "11  ExtraTreesClassifier(bootstrap=False, class_we...   \n",
       "12  BaggingClassifier(base_estimator=None, bootstr...   \n",
       "13  GradientBoostingClassifier(criterion='friedman...   \n",
       "14  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "15  LogisticRegression(C=0.01, class_weight=None, ...   \n",
       "16  RandomForestClassifier(bootstrap=True, class_w...   \n",
       "17  AdaBoostClassifier(algorithm='SAMME',\\n       ...   \n",
       "18  ExtraTreesClassifier(bootstrap=False, class_we...   \n",
       "19  BaggingClassifier(base_estimator=None, bootstr...   \n",
       "20  GradientBoostingClassifier(criterion='friedman...   \n",
       "\n",
       "                                           parameters   auc-roc  \\\n",
       "0   {'criterion': 'gini', 'max_depth': 10, 'min_sa...  0.649453   \n",
       "1                        {'C': 0.01, 'penalty': 'l1'}  0.649891   \n",
       "2   {'max_depth': 10, 'max_features': 'sqrt', 'min...  0.688447   \n",
       "3         {'algorithm': 'SAMME', 'n_estimators': 100}  0.666279   \n",
       "4   {'criterion': 'gini', 'max_depth': 10, 'max_fe...  0.634259   \n",
       "5   {'max_features': 50, 'max_samples': 50, 'n_est...  0.537292   \n",
       "6   {'learning_rate': 0.1, 'max_depth': 10, 'n_est...  0.667772   \n",
       "7   {'criterion': 'gini', 'max_depth': 10, 'min_sa...  0.640871   \n",
       "8                        {'C': 0.01, 'penalty': 'l1'}  0.640417   \n",
       "9   {'max_depth': 10, 'max_features': 'sqrt', 'min...  0.682569   \n",
       "10        {'algorithm': 'SAMME', 'n_estimators': 100}  0.676769   \n",
       "11  {'criterion': 'gini', 'max_depth': 10, 'max_fe...  0.623009   \n",
       "12  {'max_features': 50, 'max_samples': 50, 'n_est...  0.558968   \n",
       "13  {'learning_rate': 0.1, 'max_depth': 10, 'n_est...  0.606796   \n",
       "14  {'criterion': 'gini', 'max_depth': 10, 'min_sa...  0.620938   \n",
       "15                       {'C': 0.01, 'penalty': 'l1'}  0.624321   \n",
       "16  {'max_depth': 10, 'max_features': 'sqrt', 'min...  0.670367   \n",
       "17        {'algorithm': 'SAMME', 'n_estimators': 100}  0.657055   \n",
       "18  {'criterion': 'gini', 'max_depth': 10, 'max_fe...  0.620706   \n",
       "19  {'max_features': 50, 'max_samples': 50, 'n_est...  0.547968   \n",
       "20  {'learning_rate': 0.1, 'max_depth': 10, 'n_est...  0.625309   \n",
       "\n",
       "    baseline_at_1  baseline_at_2      ...       precision_at_20  \\\n",
       "0        0.002268       0.001133      ...              0.390015   \n",
       "1        0.002268       0.001133      ...              0.439828   \n",
       "2        0.002268       0.001133      ...              0.456923   \n",
       "3        0.002268       0.001133      ...              0.436998   \n",
       "4        0.002268       0.001133      ...              0.420469   \n",
       "5        0.002268       0.001133      ...              0.334654   \n",
       "6        0.002268       0.001133      ...              0.444809   \n",
       "7        0.004608       0.002304      ...              0.460493   \n",
       "8        0.004608       0.002304      ...              0.460723   \n",
       "9        0.004608       0.002304      ...              0.505413   \n",
       "10       0.004608       0.002304      ...              0.502649   \n",
       "11       0.004608       0.002304      ...              0.444368   \n",
       "12       0.004608       0.002304      ...              0.361437   \n",
       "13       0.004608       0.002304      ...              0.406358   \n",
       "14       0.003040       0.001517      ...              0.287925   \n",
       "15       0.003040       0.001517      ...              0.380916   \n",
       "16       0.003040       0.001517      ...              0.406098   \n",
       "17       0.003040       0.001517      ...              0.391383   \n",
       "18       0.003040       0.001517      ...              0.372725   \n",
       "19       0.003040       0.001517      ...              0.291717   \n",
       "20       0.003040       0.001517      ...              0.371056   \n",
       "\n",
       "    precision_at_30  precision_at_50  recall_at_1  recall_at_2  recall_at_5  \\\n",
       "0          0.372528         0.376579     0.009465     0.015908     0.058941   \n",
       "1          0.416830         0.375809     0.015749     0.033169     0.082883   \n",
       "2          0.438415         0.397546     0.020840     0.038498     0.089405   \n",
       "3          0.417509         0.381379     0.017738     0.035953     0.086064   \n",
       "4          0.398491         0.361364     0.018772     0.035396     0.082326   \n",
       "5          0.318868         0.332428     0.012249     0.029828     0.063315   \n",
       "6          0.423774         0.386044     0.017579     0.034839     0.082962   \n",
       "7          0.423833         0.417028     0.002625     0.016334     0.060668   \n",
       "8          0.448403         0.402377     0.017792     0.033834     0.082252   \n",
       "9          0.477887         0.431862     0.016480     0.035438     0.087648   \n",
       "10         0.480498         0.424952     0.017938     0.034272     0.084439   \n",
       "11         0.425676         0.392795     0.014729     0.028730     0.073064   \n",
       "12         0.354883         0.359163     0.013709     0.023625     0.066501   \n",
       "13         0.405559         0.382567     0.012250     0.024792     0.066647   \n",
       "14         0.312399         0.331553     0.012400     0.021375     0.063061   \n",
       "15         0.363875         0.328519     0.018186     0.032829     0.076169   \n",
       "16         0.385619         0.350485     0.019131     0.037317     0.091993   \n",
       "17         0.369842         0.339502     0.015588     0.034837     0.078177   \n",
       "18         0.351436         0.321359     0.016769     0.033538     0.078059   \n",
       "19         0.215008         0.366323     0.004724     0.020076     0.037907   \n",
       "20         0.353560         0.325667     0.016887     0.033774     0.080657   \n",
       "\n",
       "    recall_at_10  recall_at_20  recall_at_30  recall_at_50  \n",
       "0       0.094178      0.274022      0.392619      0.661470  \n",
       "1       0.162345      0.309020      0.439310      0.660118  \n",
       "2       0.173481      0.321031      0.462059      0.698298  \n",
       "3       0.165208      0.307031      0.440025      0.669901  \n",
       "4       0.157731      0.295418      0.419981      0.634744  \n",
       "5       0.117165      0.235126      0.336064      0.583917  \n",
       "6       0.163618      0.312520      0.446627      0.678094  \n",
       "7       0.114044      0.291527      0.402508      0.660055  \n",
       "8       0.156482      0.291673      0.425842      0.636867  \n",
       "9       0.170920      0.319965      0.453843      0.683535  \n",
       "10      0.165670      0.318215      0.456322      0.672597  \n",
       "11      0.148024      0.281318      0.404258      0.621700  \n",
       "12      0.120461      0.228817      0.337028      0.568470  \n",
       "13      0.129357      0.257255      0.385154      0.605513  \n",
       "14      0.122697      0.224138      0.364785      0.645253  \n",
       "15      0.154346      0.296528      0.424894      0.639348  \n",
       "16      0.174303      0.316131      0.450283      0.682097  \n",
       "17      0.128248      0.304676      0.431861      0.660723  \n",
       "18      0.154228      0.290151      0.410368      0.625413  \n",
       "19      0.098252      0.227090      0.251063      0.712919  \n",
       "20      0.153991      0.288852      0.412848      0.633798  \n",
       "\n",
       "[21 rows x 36 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
